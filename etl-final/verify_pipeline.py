"""
ETL Pipeline Verification Script
Checks all components of the ETL pipeline
"""
import requests
import json

print("=" * 60)
print("ETL PIPELINE VERIFICATION")
print("=" * 60)

# 1. Check Kafka Topics (via Kafka UI or direct connection)
print("\n1. KAFKA TOPICS STATUS")
print("-" * 60)
print("Check Kafka UI at http://localhost:8081 for topic statistics")
print("Expected:")
print("  - connection_topic: 1+ messages")
print("  - schema_topic: 7+ messages")
print("  - extracted_rows_topic: 10,000+ messages")
print("  - clean_rows_topic: 10,000+ messages")
print("  - load_rows_topic: 10,000+ messages")

# 2. Check ClickHouse
print("\n2. CLICKHOUSE STATUS")
print("-" * 60)
try:
    import subprocess
    result = subprocess.run(
        ['docker', 'exec', 'clickhouse', 'clickhouse-client', 
         '-u', 'etl_user', '--password', 'etl_pass123', '-d', 'etl',
         '--query', 'SHOW TABLES'],
        capture_output=True,
        text=True,
        timeout=10
    )
    if result.returncode == 0:
        tables = result.stdout.strip().split('\n')
        print(f"‚úÖ Connected to ClickHouse")
        print(f"‚úÖ Database 'etl' exists")
        print(f"‚úÖ Tables found: {len(tables)}")
        for table in tables:
            if table:
                count_result = subprocess.run(
                    ['docker', 'exec', 'clickhouse', 'clickhouse-client',
                     '-u', 'etl_user', '--password', 'etl_pass123', '-d', 'etl',
                     '--query', f'SELECT count() FROM {table}'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                count = count_result.stdout.strip() if count_result.returncode == 0 else "N/A"
                print(f"   - {table}: {count} rows")
    else:
        print(f"‚ùå Error connecting to ClickHouse: {result.stderr}")
except Exception as e:
    print(f"‚ùå Error: {e}")

# 3. Check SurrealDB
print("\n3. SURREALDB STATUS")
print("-" * 60)
try:
    response = requests.post(
        "http://localhost:8000/sql",
        auth=("root", "root"),
        headers={"Content-Type": "text/plain", "Accept": "application/json"},
        data="USE NS bi_etl; USE DB etl_logs; SELECT count() FROM upload_logs;",
        timeout=5
    )
    if response.status_code == 200:
        result = response.json()
        if len(result) >= 3 and result[2].get('status') == 'OK':
            count = result[2].get('result', [0])[0] if result[2].get('result') else 0
            print(f"‚úÖ Connected to SurrealDB")
            print(f"‚úÖ Upload logs: {count} entries")
        else:
            print(f"‚ö†Ô∏è  SurrealDB query returned: {result}")
    else:
        print(f"‚ùå SurrealDB connection failed: {response.status_code}")
except Exception as e:
    print(f"‚ùå Error: {e}")

# 4. Check Services
print("\n4. DOCKER SERVICES STATUS")
print("-" * 60)
services = [
    'connector-service',
    'extractor-service', 
    'transformer-service',
    'loader-service',
    'metadata-service'
]
try:
    result = subprocess.run(
        ['docker', 'ps', '--format', '{{.Names}}\t{{.Status}}'],
        capture_output=True,
        text=True,
        timeout=10
    )
    for service in services:
        if service in result.stdout:
            print(f"‚úÖ {service}: Running")
        else:
            print(f"‚ùå {service}: Not running")
except Exception as e:
    print(f"‚ùå Error checking services: {e}")

# 5. Summary
print("\n" + "=" * 60)
print("VERIFICATION SUMMARY")
print("=" * 60)
print("""
‚úÖ Pipeline Components:
   - Connector: Receiving uploads
   - Extractor: Processing files (10K+ rows extracted)
   - Transformer: Cleaning data (10K+ rows transformed)
   - Loader: Connected to ClickHouse, creating tables
   - Metadata: Ready to log statuses

‚ö†Ô∏è  Known Issue:
   - ClickHouse permission error preventing data writes
   - This is a Docker volume permission issue on Windows
   - Tables are created but data insertion is blocked

üí° Solution:
   - Fix ClickHouse data directory permissions
   - Or use batch inserts instead of single-row inserts
   - Or configure ClickHouse to use internal storage
""")

print("\nTo view real-time logs:")
print("  docker logs -f extractor-service")
print("  docker logs -f transformer-service")
print("  docker logs -f loader-service")

