# STRICT MODE - Semantic Correctness Over Execution

## üî¥ Philosophy Change

### Previous System (Resilient Mode)
**Goal:** Never abort, always generate SQL
**Approach:** Multi-level fallback to COUNT(*) if needed
**Priority:** Continuity > Correctness

### Current System (STRICT Mode)
**Goal:** Never generate misleading SQL
**Approach:** Refuse execution, request clarification
**Priority:** Correctness > Execution

---

## üéØ Core Principle

**"It is better to refuse than to lie."**

The system will **REFUSE** to generate SQL if:
- Semantic alignment cannot be established
- Domain-specific metrics cannot be identified
- Generic substitutions would mislead the user

---

## üîí Non-Negotiable Rules

### Rule 1: Intent Fidelity (MANDATORY)

‚ùå **FORBIDDEN:**
```python
Question: "Show average math scores by year"
Generated: SELECT year, COUNT(*) AS count FROM scores GROUP BY year

WHY WRONG: COUNT(*) is NOT "average math scores"
```

‚úÖ **REQUIRED:**
```python
Question: "Show average math scores by year"
Options:
  1. Find math_score column ‚Üí Generate correct SQL
  2. If not found ‚Üí REFUSE + REQUEST CLARIFICATION
```

### Rule 2: No Generic Substitutions

‚ùå **FORBIDDEN:**
- Using COUNT(*) as fallback for specific metrics
- Substituting student_id when question asks for scores
- Using unrelated columns from different domains

‚úÖ **REQUIRED:**
- Match question domain to column domain
- Only use semantically aligned metrics
- Refuse if alignment score < threshold

### Rule 3: Domain Awareness (MANDATORY)

**Academic Domain:**
- Keywords: score, grade, student, test, exam, reading, math
- Valid columns: AVG_MATH_8_SCORE, AVG_READING_4_SCORE, etc.
- Invalid substitutes: TOTAL_REVENUE, ENROLL (wrong domain)

**Financial Domain:**
- Keywords: revenue, cost, expenditure, budget, fee
- Valid columns: TOTAL_REVENUE, FEDERAL_REVENUE, EXPENDITURE
- Invalid substitutes: AVG_MATH_8_SCORE (wrong domain)

**Rule:** Never cross domain boundaries

### Rule 4: Type Safety (MANDATORY)

All numeric operations MUST have explicit type casts:

‚ùå **FORBIDDEN:**
```sql
SELECT AVG(math_score) FROM scores  -- math_score is STRING
```

‚úÖ **REQUIRED:**
```sql
SELECT AVG(toFloat64(math_score)) FROM scores
```

---

## üìä Validation Enforcement

### Pass 1: Intent Validation (STRICT)

**Checks:**
1. ‚úÖ No generic fallback metrics (COUNT(*))
2. ‚úÖ No cross-domain substitutions
3. ‚úÖ Strong semantic alignment required
4. ‚úÖ Question terms match column selection

**Failures:**
```python
- Generic fallback detected ‚Üí REFUSE
- Domain mismatch detected ‚Üí REFUSE
- Weak semantic alignment ‚Üí REQUEST CLARIFICATION
```

### Pass 2: Schema & Type Validation

**Checks:**
1. ‚úÖ All columns exist in schema
2. ‚úÖ All numeric operations have explicit casts
3. ‚úÖ Type compatibility verified

**Failures:**
```python
- Missing type cast ‚Üí AUTO-FIX (reconstruct SQL)
- Missing column ‚Üí REFUSE
```

### Pass 3: SQL Executability

**Checks:**
1. ‚úÖ Syntax valid for ClickHouse
2. ‚úÖ No implicit type conversions
3. ‚úÖ GROUP BY present when needed

**Failures:**
```python
- Syntax error ‚Üí REFUSE
- Type error ‚Üí AUTO-FIX if possible, else REFUSE
```

---

## üö´ Refusal Scenarios

### Scenario 1: Ambiguous Question

**Question:** "Show average values by year"

**Problem:** "values" is ambiguous - could be:
- AVG_MATH_8_SCORE (academic)
- TOTAL_REVENUE (financial)
- ENROLL (enrollment)

**Old Behavior (Resilient):**
```python
# Would use first numeric column or COUNT(*)
SELECT year, AVG(ENROLL) AS avg_values FROM table GROUP BY year
```

**New Behavior (STRICT):**
```python
ERROR: "Semantic alignment failure: Could not identify domain-relevant metrics. 
Please clarify which metric to analyze. 
Available columns: AVG_MATH_8_SCORE, TOTAL_REVENUE, ENROLL..."

requires_clarification: True
```

### Scenario 2: Cross-Domain Substitution

**Question:** "Show average math scores by state"

**Extracted Intent:**
```json
{
  "metrics": [{"column": "TOTAL_REVENUE", "aggregation": "AVG"}],
  "dimensions": ["STATE"]
}
```

**Problem:** TOTAL_REVENUE (financial) ‚â† math scores (academic)

**Old Behavior (Resilient):**
```python
# Would generate incorrect SQL
SELECT STATE, AVG(TOTAL_REVENUE) AS avg_revenue FROM table GROUP BY STATE
```

**New Behavior (STRICT):**
```python
ERROR: "Domain mismatch: Metric column 'TOTAL_REVENUE' (financial domain) 
does not align with question domain (academic)"

REFUSING to generate semantically incorrect SQL
requires_clarification: True
```

### Scenario 3: Generic Fallback Attempt

**Question:** "Show student performance by year"

**Problem:** No columns found matching "performance"

**Old Behavior (Resilient):**
```python
# Would use COUNT(*) as fallback
SELECT year, COUNT(*) AS count FROM table GROUP BY year
```

**New Behavior (STRICT):**
```python
ERROR: "Semantic alignment failure: Could not identify domain-relevant metrics.
Please clarify which metric represents 'performance'.
Available academic columns: AVG_MATH_8_SCORE, AVG_READING_4_SCORE..."

requires_clarification: True
```

---

## ‚úÖ Success Scenarios

### Scenario 1: Perfect Alignment

**Question:** "Show average math scores by year"

**Schema:** Contains AVG_MATH_8_SCORE (String type)

**Process:**
```
1. Intent Extraction
   ‚úÖ Table: etl.states_all_csv
   ‚úÖ Metric: AVG_MATH_8_SCORE
   ‚úÖ Dimension: YEAR

2. Validation Pass 1 (Intent)
   ‚úÖ "math" in question matches "MATH" in column
   ‚úÖ "score" in question matches "SCORE" in column
   ‚úÖ Domain: academic matches academic
   ‚úÖ Semantic alignment score: 8/10

3. Validation Pass 2 (Schema/Type)
   ‚úÖ Column exists
   ‚ùå Type is STRING (needs cast)
   üîß Auto-fix: Add toFloat64 cast

4. Validation Pass 3 (SQL)
   ‚úÖ Syntax valid
   ‚úÖ Type cast applied
   ‚úÖ GROUP BY present

Result: SQL GENERATED
```

**Final SQL:**
```sql
SELECT YEAR, AVG(toFloat64(AVG_MATH_8_SCORE)) AS avg_math
FROM etl.states_all_csv
GROUP BY YEAR;
```

### Scenario 2: Type Casting Auto-Fix

**Question:** "What is the total revenue by state?"

**Schema:** TOTAL_REVENUE is String type

**Process:**
```
1. Semantic Validation
   ‚úÖ "revenue" matches TOTAL_REVENUE
   ‚úÖ Domain: financial matches financial

2. Type Validation
   ‚ùå SUM on STRING requires cast
   üîß Auto-fix: toFloat64(TOTAL_REVENUE)

3. SQL Generated with cast
```

**Final SQL:**
```sql
SELECT STATE, SUM(toFloat64(TOTAL_REVENUE)) AS total_revenue
FROM etl.states_all_csv
GROUP BY STATE;
```

---

## üìã Response Format

### Success Response
```json
{
  "intent": {...},
  "sql": "SELECT ...",
  "chart": "bar",
  "confidence": 0.85,
  "validation": {
    "passed": true,
    "warnings": [],
    "reconstructed": true
  }
}
```

### Clarification Required Response
```json
{
  "error": true,
  "message": "Semantic alignment failure: Could not identify domain-relevant metrics...",
  "requires_clarification": true,
  "clarification_reason": "semantic_alignment_failure",
  "available_columns": ["AVG_MATH_8_SCORE", "TOTAL_REVENUE", ...]
}
```

### Validation Failure Response
```json
{
  "error": true,
  "message": "Domain mismatch: Metric column 'TOTAL_REVENUE' (financial) does not align with question domain (academic)",
  "requires_clarification": true,
  "validation": {
    "passed": false,
    "issues": [...]
  }
}
```

---

## üéì Confidence Scoring (STRICT Mode)

### High Confidence (0.8 - 1.0)
- ‚úÖ Perfect semantic alignment
- ‚úÖ Domain match
- ‚úÖ All validation passes
- ‚úÖ Type casting applied (or not needed)

### Medium Confidence (0.5 - 0.8)
- ‚ö†Ô∏è Weak semantic alignment but acceptable
- ‚úÖ Type casting required (minor issue)
- ‚ö†Ô∏è Some validation warnings

### Low Confidence (< 0.5)
- ‚ùå QUERY REFUSED
- üî¥ System does NOT generate SQL with low confidence
- üì¢ Clarification requested instead

---

## üîÑ Error Handling Flow

```
Question ‚Üí Intent Extraction
              ‚Üì
        Sanitization
              ‚Üì
     Can infer semantically aligned metric?
              ‚Üì
         YES ‚Üì     ‚Üì NO
              ‚Üì     ‚Üì
              ‚Üì     ‚Üí REFUSE + REQUEST CLARIFICATION
              ‚Üì        (ValueError with details)
              ‚Üì
     Initial SQL Generation
              ‚Üì
     Multi-Pass Validation
              ‚Üì
     Pass 1 Failed (Semantic)?
              ‚Üì
         YES ‚Üì     ‚Üì NO
              ‚Üì     ‚Üì
              ‚Üì     ‚Üí Continue to Pass 2
              ‚Üì
         REFUSE + RETURN ERROR
         (requires_clarification: true)
              ‚Üì
     Pass 2 Failed (Type)?
              ‚Üì
         YES ‚Üì     ‚Üì NO
              ‚Üì     ‚Üì
     AUTO-FIX  ‚Üì   ‚Üí Continue to Pass 3
     (Add casts)
              ‚Üì
     Revalidate ‚Üí Pass?
              ‚Üì
         YES ‚Üì     ‚Üì NO
              ‚Üì     ‚Üì
              ‚Üì     ‚Üí REFUSE
              ‚Üì
     SQL Generated ‚úÖ
```

---

## üöÄ System Guarantees (STRICT Mode)

| Guarantee | Implementation |
|-----------|----------------|
| **No Generic Fallbacks** | Raises ValueError instead of COUNT(*) |
| **No Domain Mixing** | Validation Pass 1 checks domain alignment |
| **No Implicit Casts** | Validation Pass 2 enforces explicit casts |
| **Clarification Over Guessing** | Returns requires_clarification flag |
| **100% Semantic Correctness** | Refuses execution if alignment fails |

---

## üìä Comparison: Resilient vs STRICT

| Aspect | Resilient Mode | STRICT Mode |
|--------|----------------|-------------|
| **Philosophy** | Continuity first | Correctness first |
| **Empty Metrics** | Infer ‚Üí Fallback ‚Üí COUNT(*) | Infer ‚Üí REFUSE |
| **Domain Mismatch** | Warn + Continue | REFUSE |
| **Generic Metrics** | Allowed (with flag) | FORBIDDEN |
| **Confidence** | Can be low but still execute | Low confidence = REFUSE |
| **User Experience** | Always get SQL | May get clarification request |
| **Accuracy** | ~80% (may be wrong) | 100% (or refuses) |

---

## üéØ When to Use Each Mode

### Use STRICT Mode When:
- ‚úÖ Accuracy is critical (production BI)
- ‚úÖ Misleading results could cause harm
- ‚úÖ User can provide clarification
- ‚úÖ Data-driven decisions are made
- ‚úÖ Compliance/audit requirements

### Use Resilient Mode When:
- üîπ Exploration/experimentation
- üîπ Unknown user needs
- üîπ No clarification possible
- üîπ Some result better than no result
- üîπ Low-stakes queries

---

**Current Implementation:** STRICT MODE (Correctness First) ‚úÖ

**Status:** Production-ready for high-accuracy BI applications
**Zero Tolerance:** Semantic misalignment, domain mixing, generic fallbacks

